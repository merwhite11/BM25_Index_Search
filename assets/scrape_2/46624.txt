How to remove redshift from galaxy spectra in Python?

Hello I extracted a spectrum from the central region of the 2D spectrum of the major axis from NGC 4697 (I just took a central row in the 2D data set, see this question for more information: How to extract galaxy spectra for different radii in Python for spectra taken by long slit spectrograph?). I also have got a template spectrum from the K2-III star hd132345. Here both spectras are plotted:

One can clearly see that the absorption lines in the galaxy spectrum have been broadened, due to the superposition of many stellar spectra, each one having a individual velocity along the line of sight. I now have done some preprocessing steps to keep on working with the spectra in fourier space later. These steps included: cutting off pixels at both ends of the spectrum, removing the continuum, tapering both spectra with a window function using np.blackman(). The result can be seen here:

To further work with the spectra I want to remove/measure the redshift from the galaxy, to use them later in the FCQ algorithm to determine the velocity distribution along the line of sight and therefore the kinematics of NGC 4697. One can clearly see the 3 dominant lines in the template spectrum arround the x-value of 8.55, these lines should be the Magnesium triplet, which has its wavelengths at round about 5200 Angstroems ( note that the spectra are logarithmically rebinned). I wanted to use these lines to determine the redshift of the galaxy. The triplet in the galaxy has involved into a doublet, due to the broadening. I did set up vertical lines at the peaks of the absorption lines and calculated the shift graphically. One can clearly see that the galaxy absorption lines have been shifted towards the red end of the spectrum. I wanted to know if there is a more elegant/common way to tackle this problem, since it is probably one of the most basic things to do in Astronomy. I just could not find a sophisticated answer for a Python solution in the internet and did not want to use a prewritten funciton, for educational purposes. My goal is it to not have to look for the x values of the peaks manually, to make the problem easier when you are working with more spectra. The spectra in the MG-Triplet region with redshift look as follows. And after I subtracted the redshift. . Here I just calculated: loglam_gal = loglam_gal - (8.55702-8.55323). Is there a better way to do this and did I even do it correct ? Both spectra after removing the redshift from the galaxy look as follows:

I have calculated the redshift from my graphically measured wavelengths to be: z = 0.003797. In Wikipedia it says z= 0.004140 for NGC 4697.